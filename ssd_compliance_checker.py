#!/usr/bin/env python3
"""
SSD Theory Compliance Checker - SSDç†è«–æº–æ‹ ãƒã‚§ãƒƒã‚«ãƒ¼

ğŸ”— åŸºç¤ç†è«–ãƒªãƒã‚¸ãƒˆãƒª: https://github.com/HermannDegner/Structural-Subjectivity-Dynamics

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®SSDç†è«–æº–æ‹ çŠ¶æ³ã‚’æ¤œè¨¼ã—ã€ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚
"""

import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
import re
from dataclasses import dataclass

from ssd_theory_reference import get_ssd_reference, validate_against_ssd_theory

@dataclass
class ComplianceReport:
    """SSDç†è«–æº–æ‹ ãƒ¬ãƒãƒ¼ãƒˆ"""
    file_path: str
    compliance_score: float
    found_concepts: List[str] 
    missing_concepts: List[str]
    theoretical_gaps: List[str]
    recommendations: List[str]
    kappa_memory_implementation: Dict[str, Any]

class SSDComplianceChecker:
    """SSDç†è«–æº–æ‹ ãƒã‚§ãƒƒã‚«ãƒ¼"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.ssd_ref = get_ssd_reference()
        
        # SSDç†è«–å¿…é ˆæ¦‚å¿µ
        self.required_concepts = {
            "coherence_inertia_kappa": r"(Îº|kappa|coherence[_\s]*inertia)",
            "memory_system": r"(è¨˜æ†¶|memory|experience|learning)",
            "meaning_pressure": r"(æ„å‘³åœ§|meaning[_\s]*pressure|p\(t\))",
            "alignment": r"(æ•´åˆ|alignment)",
            "leap": r"(è·³èº|leap|jump)",
            "four_layer": r"(å››å±¤|four[_\s]*layer|ç‰©ç†å±¤|åŸºå±¤|ä¸­æ ¸å±¤|ä¸Šå±¤)",
            "structure": r"(æ§‹é€ |structure)",
            "subjective": r"(ä¸»è¦³|subjective)",
            "ssd_theory": r"(SSD|Structure[_\s]*Subjective[_\s]*Dynamics|æ§‹é€ ä¸»è¦³åŠ›å­¦)"
        }
        
        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.important_files = [
            "**/*.py",
            "**/*.md", 
            "**/*.txt"
        ]
        
        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.exclude_patterns = [
            "__pycache__",
            ".git",
            "*.pyc",
            "*.log"
        ]
    
    def scan_file_for_concepts(self, file_path: Path) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®SSDæ¦‚å¿µã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
        except Exception as e:
            return {"error": str(e), "concepts": {}}
        
        found_concepts = {}
        for concept_name, pattern in self.required_concepts.items():
            matches = re.findall(pattern, content, re.IGNORECASE)
            found_concepts[concept_name] = len(matches) > 0
        
        # ç‰¹åˆ¥ãƒã‚§ãƒƒã‚¯: Îº=è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ 
        kappa_memory_check = self.ssd_ref.check_kappa_memory_implementation(content)
        
        return {
            "concepts": found_concepts,
            "content_length": len(content),
            "kappa_memory": kappa_memory_check,
            "ssd_references": self._count_ssd_references(content)
        }
    
    def _count_ssd_references(self, content: str) -> Dict[str, int]:
        """SSDç†è«–å‚ç…§ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        references = {
            "github_repo_mentions": len(re.findall(r"HermannDegner/Structural-Subjectivity-Dynamics", content)),
            "theory_mentions": len(re.findall(r"SSD|Structure\s*Subjective\s*Dynamics|æ§‹é€ ä¸»è¦³åŠ›å­¦", content, re.IGNORECASE)),
            "kappa_memory_mentions": len(re.findall(r"Îº.*è¨˜æ†¶|kappa.*memory|æ•´åˆæ…£æ€§.*è¨˜æ†¶", content, re.IGNORECASE))
        }
        return references
    
    def generate_file_report(self, file_path: Path, scan_results: Dict[str, Any]) -> ComplianceReport:
        """ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        
        concepts = scan_results.get("concepts", {})
        found_concepts = [name for name, found in concepts.items() if found]
        missing_concepts = [name for name, found in concepts.items() if not found]
        
        # ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚¹ã‚³ã‚¢è¨ˆç®—
        compliance_score = len(found_concepts) / len(self.required_concepts) if self.required_concepts else 0.0
        
        # æ¨å¥¨äº‹é …ç”Ÿæˆ
        recommendations = []
        if compliance_score < 0.5:
            recommendations.append(f"åŸºç¤ç†è«–ãƒªãƒã‚¸ãƒˆãƒªã‚’å‚ç…§ã—ã¦ãã ã•ã„: {self.ssd_ref.repo_url}")
            
        if "coherence_inertia_kappa" not in found_concepts:
            recommendations.append("æ•´åˆæ…£æ€§Îºã®æ¦‚å¿µã‚’å®Ÿè£…ã—ã¦ãã ã•ã„")
            
        if "memory_system" not in found_concepts:
            recommendations.append("Îº=è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã®ç†è«–çš„æ´å¯Ÿã‚’å®Ÿè£…ã—ã¦ãã ã•ã„")
        
        # ç†è«–çš„ã‚®ãƒ£ãƒƒãƒ—ã®ç‰¹å®š
        gaps = []
        kappa_memory = scan_results.get("kappa_memory", {})
        if kappa_memory.get("theoretical_compliance", "LOW") == "LOW":
            gaps.append("æ•´åˆæ…£æ€§Îº=è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ãŒä¸ååˆ†")
        
        return ComplianceReport(
            file_path=str(file_path),
            compliance_score=compliance_score,
            found_concepts=found_concepts,
            missing_concepts=missing_concepts,
            theoretical_gaps=gaps,
            recommendations=recommendations,
            kappa_memory_implementation=kappa_memory
        )
    
    def scan_project(self) -> List[ComplianceReport]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        
        reports = []
        
        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
        important_files = []
        for pattern in self.important_files:
            important_files.extend(self.project_root.glob(pattern))
        
        # é™¤å¤–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ•ã‚£ãƒ«ã‚¿
        filtered_files = []
        for file_path in important_files:
            if file_path.is_file() and not any(exclude in str(file_path) for exclude in self.exclude_patterns):
                filtered_files.append(file_path)
        
        print(f"ğŸ“ ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(filtered_files)}")
        
        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³
        for file_path in filtered_files:
            print(f"ğŸ” ã‚¹ã‚­ãƒ£ãƒ³ä¸­: {file_path.name}")
            
            scan_results = self.scan_file_for_concepts(file_path)
            if "error" not in scan_results:
                report = self.generate_file_report(file_path, scan_results)
                reports.append(report)
        
        return reports
    
    def generate_summary_report(self, reports: List[ComplianceReport]) -> Dict[str, Any]:
        """ç·åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        
        if not reports:
            return {"error": "ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"}
        
        # çµ±è¨ˆè¨ˆç®—
        total_files = len(reports)
        avg_compliance = sum(r.compliance_score for r in reports) / total_files
        
        high_compliance = [r for r in reports if r.compliance_score >= 0.8]
        medium_compliance = [r for r in reports if 0.5 <= r.compliance_score < 0.8]
        low_compliance = [r for r in reports if r.compliance_score < 0.5]
        
        # æœ€ã‚‚é‡è¦ãªæ¦‚å¿µã®æ™®åŠç‡
        concept_coverage = {}
        for concept in self.required_concepts.keys():
            coverage = sum(1 for r in reports if concept in r.found_concepts) / total_files
            concept_coverage[concept] = coverage
        
        # é‡è¦ãªç™ºè¦‹
        key_findings = []
        
        # Îº=è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…çŠ¶æ³
        kappa_implementations = [r.kappa_memory_implementation for r in reports if r.kappa_memory_implementation]
        high_kappa_impl = [k for k in kappa_implementations if k.get("theoretical_compliance") == "HIGH"]
        
        if len(high_kappa_impl) / total_files > 0.7:
            key_findings.append("âœ… æ•´åˆæ…£æ€§Îº=è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ãŒé©åˆ‡ã«å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™")
        else:
            key_findings.append("âš ï¸ æ•´åˆæ…£æ€§Îº=è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ã‚’æ”¹å–„ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        
        # åŸºç¤ç†è«–å‚ç…§çŠ¶æ³
        theory_refs = sum(1 for r in reports if "ssd_theory" in r.found_concepts)
        if theory_refs / total_files > 0.8:
            key_findings.append("âœ… SSDåŸºç¤ç†è«–ã¸ã®å‚ç…§ãŒå……å®Ÿã—ã¦ã„ã¾ã™")
        else:
            key_findings.append("âš ï¸ SSDåŸºç¤ç†è«–ã¸ã®å‚ç…§ã‚’å¢—ã‚„ã—ã¦ãã ã•ã„")
        
        return {
            "ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°": total_files,
            "å¹³å‡ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚¹ã‚³ã‚¢": avg_compliance,
            "é«˜ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹": len(high_compliance),
            "ä¸­ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹": len(medium_compliance), 
            "ä½ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹": len(low_compliance),
            "æ¦‚å¿µã‚«ãƒãƒ¬ãƒƒã‚¸": concept_coverage,
            "ä¸»è¦ç™ºè¦‹": key_findings,
            "åŸºç¤ç†è«–ãƒªãƒã‚¸ãƒˆãƒª": self.ssd_ref.repo_url,
            "æ¨å¥¨äº‹é …": [
                "å®šæœŸçš„ã«SSDåŸºç¤ç†è«–ãƒªãƒã‚¸ãƒˆãƒªã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                "æ•´åˆæ…£æ€§Îº=è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã®æ¦‚å¿µã‚’å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã§çµ±ä¸€ã—ã¦ãã ã•ã„",
                "æ§‹é€ è¦³ç…§ï¼ˆãƒ†ã‚ªãƒ¼ãƒªã‚¢ï¼‰ã®å§¿å‹¢ã‚’ä¿æŒã—ã¦ãã ã•ã„"
            ]
        }
    
    def export_report(self, reports: List[ComplianceReport], summary: Dict[str, Any], 
                     output_file: str = "ssd_compliance_report.md") -> None:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’Markdownå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        
        output_path = self.project_root / output_file
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("# SSDç†è«–æº–æ‹ ãƒ¬ãƒãƒ¼ãƒˆ\n\n")
            f.write(f"ğŸ”— **åŸºç¤ç†è«–ãƒªãƒã‚¸ãƒˆãƒª**: {self.ssd_ref.repo_url}\n\n")
            f.write(f"ğŸ“… **ç”Ÿæˆæ—¥æ™‚**: {self._get_current_datetime()}\n\n")
            
            # ç·åˆçµ±è¨ˆ
            f.write("## ğŸ“Š ç·åˆçµ±è¨ˆ\n\n")
            f.write(f"- **ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {summary['ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°']}\n")
            f.write(f"- **å¹³å‡ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚¹ã‚³ã‚¢**: {summary['å¹³å‡ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚¹ã‚³ã‚¢']:.2f}\n")
            f.write(f"- **é«˜ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹** (â‰¥80%): {summary['é«˜ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹']}ãƒ•ã‚¡ã‚¤ãƒ«\n")
            f.write(f"- **ä¸­ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹** (50-80%): {summary['ä¸­ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹']}ãƒ•ã‚¡ã‚¤ãƒ«\n")
            f.write(f"- **ä½ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹** (<50%): {summary['ä½ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹']}ãƒ•ã‚¡ã‚¤ãƒ«\n\n")
            
            # ä¸»è¦ç™ºè¦‹
            f.write("## ğŸ” ä¸»è¦ç™ºè¦‹\n\n")
            for finding in summary["ä¸»è¦ç™ºè¦‹"]:
                f.write(f"- {finding}\n")
            f.write("\n")
            
            # æ¦‚å¿µã‚«ãƒãƒ¬ãƒƒã‚¸
            f.write("## ğŸ“ˆ SSDæ¦‚å¿µã‚«ãƒãƒ¬ãƒƒã‚¸\n\n")
            for concept, coverage in summary["æ¦‚å¿µã‚«ãƒãƒ¬ãƒƒã‚¸"].items():
                percentage = coverage * 100
                status = "âœ…" if coverage >= 0.7 else "âš ï¸" if coverage >= 0.4 else "âŒ"
                f.write(f"- **{concept}**: {percentage:.1f}% {status}\n")
            f.write("\n")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥è©³ç´°
            f.write("## ğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥è©³ç´°\n\n")
            
            # é«˜ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«
            high_files = [r for r in reports if r.compliance_score >= 0.8]
            if high_files:
                f.write("### âœ… é«˜ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ãƒ•ã‚¡ã‚¤ãƒ« (â‰¥80%)\n\n")
                for report in sorted(high_files, key=lambda x: x.compliance_score, reverse=True):
                    f.write(f"- **{Path(report.file_path).name}**: {report.compliance_score:.1%}\n")
                f.write("\n")
            
            # æ”¹å–„ãŒå¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«
            low_files = [r for r in reports if r.compliance_score < 0.5]
            if low_files:
                f.write("### âš ï¸ æ”¹å–„ãŒå¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ« (<50%)\n\n")
                for report in sorted(low_files, key=lambda x: x.compliance_score):
                    f.write(f"- **{Path(report.file_path).name}**: {report.compliance_score:.1%}\n")
                    if report.recommendations:
                        for rec in report.recommendations[:2]:  # ä¸»è¦ãªæ¨å¥¨äº‹é …ã®ã¿
                            f.write(f"  - ğŸ’¡ {rec}\n")
                f.write("\n")
            
            # æ¨å¥¨äº‹é …
            f.write("## ğŸ’¡ æ¨å¥¨äº‹é …\n\n")
            for rec in summary["æ¨å¥¨äº‹é …"]:
                f.write(f"1. {rec}\n")
            f.write("\n")
            
            f.write("---\n")
            f.write("**ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚å®šæœŸçš„ã«å®Ÿè¡Œã—ã¦SSDç†è«–æº–æ‹ ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚**\n")
        
        print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {output_path}")
    
    def _get_current_datetime(self) -> str:
        """ç¾åœ¨æ—¥æ™‚ã‚’å–å¾—"""
        from datetime import datetime
        return datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ” SSDç†è«–æº–æ‹ ãƒã‚§ãƒƒã‚«ãƒ¼ã‚’é–‹å§‹ã—ã¾ã™...")
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’å–å¾—
    project_root = Path(__file__).parent
    print(f"ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {project_root}")
    
    # ãƒã‚§ãƒƒã‚«ãƒ¼ã‚’åˆæœŸåŒ–
    checker = SSDComplianceChecker(str(project_root))
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚¹ã‚­ãƒ£ãƒ³
    print("\nğŸ” ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ã„ã¾ã™...")
    reports = checker.scan_project()
    
    # ç·åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    print("\nğŸ“Š ç·åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
    summary = checker.generate_summary_report(reports)
    
    # ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º
    print(f"\nğŸ“‹ SSDç†è«–æº–æ‹ çŠ¶æ³:")
    print(f"å¹³å‡ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚¹ã‚³ã‚¢: {summary['å¹³å‡ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚¹ã‚³ã‚¢']:.1%}")
    print(f"é«˜ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«: {summary['é«˜ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹']}")
    print(f"æ”¹å–„ãŒå¿…è¦: {summary['ä½ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹']}")
    
    # ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    checker.export_report(reports, summary)
    
    print(f"\nğŸ”— åŸºç¤ç†è«–ãƒªãƒã‚¸ãƒˆãƒª: {checker.ssd_ref.repo_url}")
    print("âœ… SSDç†è«–æº–æ‹ ãƒã‚§ãƒƒã‚¯å®Œäº†!")

if __name__ == "__main__":
    main()